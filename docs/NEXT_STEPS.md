# グラニュート文字OCR - 次のステップ

## 現状の課題

### 精度評価結果
- **ベースライン精度**: 7.8% (文字レベル)
- **再訓練後精度**: 9.1% (文字レベル) 
- **改善幅**: +1.3% (わずかな向上)

### 主な問題点
1. **訓練データと実データのギャップ**
   - 訓練データ: 紫色の泡背景、太い文字
   - 実データ: 多様な背景、細い文字

2. **文字分割の困難さ**
   - 文字が密接している
   - 文字間隔が不規則
   - 単語内での文字配置が複雑

3. **認識エラーパターン**
   - E → C (8回)
   - O → L (6回)
   - O → C (6回)

## 推奨される改善アプローチ

### 1. エンドツーエンドモデルの実装
**優先度: 高**

文字分割に依存しない、単語全体を認識するアプローチ：
- **CRNN (Convolutional Recurrent Neural Network)**
  - CNN特徴抽出 + RNN系列認識
  - CTC (Connectionist Temporal Classification) loss
  - 文字分割不要

- **Attention-based OCR**
  - Encoder-Decoder構造
  - 文字位置を自動的に学習
  - より柔軟な認識が可能

### 2. データ拡張の強化
**優先度: 中**

実データに近い訓練データを生成：
- **文字の太さ変換**
  - Morphological変換で細い文字を生成
  - エッジ強調/弱化

- **背景の多様化**
  - 様々な色・パターンの背景を合成
  - ノイズ・ぼかしの追加

### 3. セグメンテーション改善
**優先度: 中**

現在のアプローチを改良：
- **Watershed Algorithm**
  - より精密な文字境界検出
  
- **Deep Learning based Segmentation**
  - U-Netなどでピクセルレベルの文字マスク生成

### 4. アンサンブル手法
**優先度: 低**

複数モデルの組み合わせ：
- CNN + CRNN + Tesseract
- 投票メカニズムによる最終判定
- 信頼度ベースの重み付け

## 実装計画

### フェーズ1: CRNNモデルの実装 (推定: 2-3日)
1. PyTorchでCRNN構造を実装
2. CTC lossの実装
3. 既存データでの訓練

### フェーズ2: データ拡張パイプライン (推定: 1日)
1. 文字太さ変換の実装
2. 背景合成機能の追加
3. 拡張データセットの生成

### フェーズ3: 統合と評価 (推定: 1日)
1. 新モデルをOCRサービスに統合
2. テストデータでの評価
3. パフォーマンス最適化

## 期待される成果
- 文字レベル精度: 30-50%への向上
- 単語レベル精度: 20-40%への向上
- より堅牢な認識システム

## 技術的な考慮事項
- GPUが利用可能な場合、訓練時間を大幅に短縮可能
- CRNNの実装には追加のライブラリ（warp-ctc等）が必要な場合あり
- メモリ使用量が増加する可能性があるため、バッチサイズの調整が必要